{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Logistic Regression in Python  - College Admission\n",
    "\n",
    "### Overview\n",
    "Predict college admission using Multiple Logistic Regression\n",
    " \n",
    "### Builds on\n",
    "None\n",
    "\n",
    "### Run time\n",
    "approx. 10-20 minutes\n",
    "\n",
    "### Notes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [
      "R"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 1: College Admission Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the college admission data.  Here, we have some student test scores, GPA, and Rank, followed by whether the student was admitted or not.\n",
    "\n",
    "\n",
    "|gre  |gpa  |rank |  admitted |\n",
    "|-----------------------------|\n",
    "|380  |3.61 | 3   |    no     |\n",
    "|660  |3.67 | 1   |    yes    |\n",
    "|800  |4.0  | 1   |    yes    |\n",
    "|640  |3.19 | 4   |    yes    |\n",
    "|520  |2.93 | 4   |    no     |\n",
    "|760  |3.0  | 2   |    yes    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [
      "R"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "admissions = pd.read_csv(\"/data/college-admissions/admission-data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Split Data into training and Test\n",
    "\n",
    "We will split our data into training and test so we can see how it performs.\n",
    "\n",
    "**=> TODO: Use training / test split of 70%/30% **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "train_x, test_x, train_y, test_y = train_test_split(feature_vector, \n",
    "                                                    labels, test_size=???)\n",
    "print(\"training set = \" , len(train_x))\n",
    "print(\"testing set = \" , len(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set =  70\n",
      "testing set =  30\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    " # REMOVE\n",
    "\n",
    "feature_vector = admissions.iloc[:,0:3]\n",
    "labels = admissions.iloc[:,3]\n",
    "train_x, test_x, train_y, test_y = train_test_split(feature_vector, \n",
    "                                                    labels, test_size=.3)\n",
    "print(\"training set = \" , len(train_x))\n",
    "print(\"testing set = \" , len(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 4: Run logistic regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.48324488  0.00120315 -0.49915723]\n",
      " [-0.0093794   0.00139123 -0.45382615]\n",
      " [ 0.77702984 -0.00534947  0.54565565]\n",
      " [-0.92576839  0.00115703 -0.4891325 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(train_x, train_y)\n",
    "\n",
    "print(lrModel.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Inspect Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predictions = lrModel.predict(test_x)\n",
    "confusion_matrix(test_y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 :  ROC Curve & AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(test_y, predictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b',\n",
    "label='AUC = %0.2f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.2])\n",
    "plt.ylim([-0.1,1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Run on the test data\n",
    "\n",
    "**=>TODO: transform the test data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 2, 3, 2, 3, 3, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 3, 2, 2, 3, 2, 2,\n",
       "       2, 2, 3, 2, 2, 2, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## what is the name of test dataframe?\n",
    "predictions = lrModel.predict(test_x)\n",
    "predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Calcuate Accuracy on Test Data\n",
    "\n",
    "**=>TODO: evaluate the predictions **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40000000000000002"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Run some predictions on new data\n",
    "\n",
    "Let's take some new data, and run predictions on that.\n",
    "\n",
    "**=>TODO: transform the new data in order to get feature vectors **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newdata = pd.DataFrame({'gre' : [600, 700, 800], \n",
    "                        'gpa' : [4.0, 3.5, 3.2],\n",
    "                        'rank': [1,   2,   3]}\n",
    "             )\n",
    "print(newdata)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
